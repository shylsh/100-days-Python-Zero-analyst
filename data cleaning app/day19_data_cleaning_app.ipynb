{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a data cleaning application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"diwali_sales_data.csv\"\n",
    "data_name = 'Diwali Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_master(data_path,data_name):\n",
    "    \n",
    "    print(\"Thank you for giving the details\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the path exist\n",
    "if not os.path.exists(data_path):\n",
    "    print('Please enter the correct path !')\n",
    "    #return\n",
    "else:\n",
    "    #checking the file type\n",
    "    if data_path.endswith('.csv'):\n",
    "        print(\"Dataset is csv!\")\n",
    "        data = pd.read_csv(data_path,encoding_errors ='ignore')\n",
    "    elif(data_path.endswith('.xlsx')):\n",
    "        print(\"Dataset is excel file !\")\n",
    "        data = pd.read_excel(data_path,encoding_errors ='ignore')\n",
    "    else:\n",
    "        print(\"Unknown file Type\")\n",
    "        #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing number of records\n",
    "print(f'Dataset cotnain total rows : {data.shape[0]}\\n Total Columns :{data.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start cleaning\n",
    "duplicates = data.duplicated()\n",
    "total_duplicates = data.duplicated().sum()\n",
    "\n",
    "print(f\"Datasets has {total_duplicates} duplicates\")\n",
    "\n",
    "# Saving the duplicates\n",
    "if total_duplicates>0:\n",
    "    duplicate_records = data[duplicates]\n",
    "    duplicate_records.to_csv(f'{data_name}_duplicates.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting duplicates\n",
    "df = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the missing values\n",
    "total_missing_values = df.isnull().sum().sum()\n",
    "missing_value_columns = df.isnull().sum()\n",
    "\n",
    "print(f'Dataset has total missing values : {total_missing_values}')\n",
    "print(f'Dataset contain missing value by columns \\n {missing_value_columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with missing values\n",
    "# fillna - int and float\n",
    "# dropna - any object\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "for col in columns:\n",
    "    # filling mean for numeric columns all rows\n",
    "    if df[col].dtype in(int, float):\n",
    "        df[col]=df[col].fillna(df[col].mean())\n",
    "    else:\n",
    "        # dropping all rows with non- number missing records\n",
    "        df.dropna(subset=col, inplace = True)\n",
    "        \n",
    "# Dropping columns with all NaN values\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Dropping rows with all NaN values\n",
    "df.dropna(axis = 0,how='all', inplace = True)\n",
    "\n",
    "# Data is cleaned\n",
    "print(f\"The Dataset is cleaned!\\nNumber of Rows :{df.shape[0]}\\nNumber of Columns: {df.shape[1]}\")\n",
    "\n",
    "# Saving the clean dataset\n",
    "df.to_csv(f'{data_name}_Cleaned_Data.csv',index = None)\n",
    "print(\"Dataset is saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset is cleaned!\n",
      "Number of Rows :11243\n",
      "Number of Columns: 12\n",
      "Dataset is saved\n",
      "Thank you for giving the details\n",
      "Dataset is csv!\n",
      "Dataset contain total rows : 995\n",
      " Total Columns :28\n",
      "Datasets has total duplicates :0\n",
      "Dataset has total missing values : 1627\n",
      "Dataset contain missing value by columns \n",
      " rank                                         0\n",
      "Youtuber                                     6\n",
      "subscribers                                  0\n",
      "video views                                  0\n",
      "category                                    46\n",
      "Title                                        5\n",
      "uploads                                      0\n",
      "Country                                    122\n",
      "Abbreviation                               122\n",
      "channel_type                                30\n",
      "video_views_rank                             1\n",
      "country_rank                               116\n",
      "channel_type_rank                           33\n",
      "video_views_for_the_last_30_days            56\n",
      "lowest_monthly_earnings                      0\n",
      "highest_monthly_earnings                     0\n",
      "lowest_yearly_earnings                       0\n",
      "highest_yearly_earnings                      0\n",
      "subscribers_for_last_30_days               337\n",
      "created_year                                 5\n",
      "created_month                                5\n",
      "created_date                                 5\n",
      "Gross tertiary education enrollment (%)    123\n",
      "Population                                 123\n",
      "Unemployment rate                          123\n",
      "Urban_population                           123\n",
      "Latitude                                   123\n",
      "Longitude                                  123\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# This is a data cleaning application\n",
    "# importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# data_path = \"diwali_sales_data.csv\"\n",
    "# data_name = 'Diwali Sales'\n",
    "\n",
    "def data_cleaning_master(data_path,data_name):\n",
    "\n",
    "    print(\"Thank you for giving the details\")\n",
    "    \n",
    "    \n",
    "# checking if the path exist\n",
    "    if not os.path.exists(data_path):\n",
    "        print('Please enter the correct path !')\n",
    "        return\n",
    "    else:\n",
    "        #checking the file type\n",
    "        if data_path.endswith('.csv'):\n",
    "            print(\"Dataset is csv!\")\n",
    "            data = pd.read_csv(data_path,encoding_errors ='ignore')\n",
    "            \n",
    "        elif(data_path.endswith('.xlsx')):\n",
    "            print(\"Dataset is excel file !\")\n",
    "            data = pd.read_excel(data_path)\n",
    "            \n",
    "        else:\n",
    "            print(\"Unknown file Type\")\n",
    "            return\n",
    "    # showing number of records\n",
    "    print(f'Dataset contain total rows : {data.shape[0]}\\n Total Columns :{data.shape[1]}')\n",
    "    #start cleaning\n",
    "    duplicates = data.duplicated()\n",
    "    total_duplicates = data.duplicated().sum()\n",
    "\n",
    "    print(f\"Datasets has total duplicates :{total_duplicates}\")\n",
    "\n",
    "    # Saving the duplicates\n",
    "    if total_duplicates>0:\n",
    "        duplicate_records = data[duplicates]\n",
    "        duplicate_records.to_csv(f'{data_name}_duplicates.csv', index = None)\n",
    "    # deleting duplicates\n",
    "    df = data.drop_duplicates()\n",
    "    #find the missing values\n",
    "    total_missing_values = df.isnull().sum().sum()\n",
    "    missing_value_columns = df.isnull().sum()\n",
    "\n",
    "    print(f'Dataset has total missing values : {total_missing_values}')\n",
    "    print(f'Dataset contain missing value by columns \\n {missing_value_columns}')\n",
    "    \n",
    "    # dealing with missing values\n",
    "    # fillna - int and float\n",
    "    # dropna - any object\n",
    "\n",
    "    columns = df.columns\n",
    "\n",
    "    for col in columns:\n",
    "        # filling mean for numeric columns all rows\n",
    "        if df[col].dtype in(int, float):\n",
    "            df[col]=df[col].fillna(df[col].mean())\n",
    "            \n",
    "        else:\n",
    "            # dropping all rows with non- number missing records\n",
    "            df.dropna(subset=col, inplace = True)\n",
    "\n",
    "# # Dropping columns with all NaN values\n",
    "# df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# # Dropping rows with all NaN values\n",
    "# df.dropna(axis = 0,how='all', inplace = True)\n",
    "\n",
    "# Data is cleaned\n",
    "print(f\"The Dataset is cleaned!\\nNumber of Rows :{df.shape[0]}\\nNumber of Columns: {df.shape[1]}\")\n",
    "\n",
    "# Saving the clean dataset\n",
    "df.to_csv(f'{data_name}_Cleaned_Data.csv',index = None)\n",
    "print(\"Dataset is saved\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "# Ask path and file name\n",
    "    data_path = input('Enter the path : ')\n",
    "    data_name = input('Enter a file name : ')\n",
    "    \n",
    "#calling the function \n",
    "data_cleaning_master(data_path,data_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
